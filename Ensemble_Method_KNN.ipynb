{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy rate in training set is  0.718917217501\n",
      "The accuracy rate in training set is (Bag_1) 0.734970097576\n",
      "The accuracy rate in training set is (Bag_2) 0.826950393444\n",
      "The AUC score is  0.598967313696\n",
      "The AUC score is  0.591203651201\n",
      "The AUC score is  0.647451727354\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# select different feature size and run cross validation\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from itertools import cycle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "    \n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "\n",
    "# read data and standardize\n",
    "train_data = pd.read_csv(\"training_data.csv\")\n",
    "train_data_2 = train_data.iloc[:,1:]\n",
    "\n",
    "X = train_data_2.iloc[:, :-1]\n",
    "Y = train_data_2.iloc[:, -1]\n",
    "X = preprocessing.scale(X)\n",
    "# selece feature based on f_classif\n",
    "X_new = SelectKBest(f_classif, k=100)\n",
    "X_new.fit_transform(X, Y)\n",
    "X = X[:, X_new.get_support()]\n",
    "c = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "logreg = LogisticRegressionCV(penalty='l2', solver='sag', Cs=c, refit=True, cv=10, max_iter=100)\n",
    "logreg.fit(X, Y)\n",
    "score_list.append(logreg.score(X, Y))\n",
    "# print(score_list[-1])    \n",
    "\n",
    "print(\"The accuracy rate in training set is \", logreg.score(X, Y))\n",
    "\n",
    "\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(),\n",
    "                            max_samples=0.5, max_features=0.5)\n",
    "\n",
    "\n",
    "estimators = [(\"Tree\", DecisionTreeRegressor()),\n",
    "              (\"Bagging(Tree)\", BaggingRegressor(DecisionTreeRegressor()))]\n",
    "\n",
    "bagging_2 = BaggingRegressor(DecisionTreeRegressor())                                   \n",
    "\n",
    "\n",
    "Bagreg = bagging.fit(X, Y)\n",
    "Bagreg.score(X, Y)\n",
    "print(\"The accuracy rate in training set is (Bag_1)\", Bagreg.score(X, Y))\n",
    "\n",
    "Bagreg_2 = bagging_2.fit(X, Y)\n",
    "Bagreg_2.score(X, Y)\n",
    "print(\"The accuracy rate in training set is (Bag_2)\", Bagreg_2.score(X, Y))\n",
    "\n",
    "\n",
    "\n",
    "# test PCA at testing dataset\n",
    "test_data = pd.read_csv(\"testing_data.csv\")\n",
    "test_data_2 = test_data.iloc[:,1:]\n",
    "\n",
    "X_test = test_data_2.iloc[:, :-1]\n",
    "Y_test = test_data_2.iloc[:, -1]\n",
    "X_test = preprocessing.scale(X_test)\n",
    "X_test = X_test[:, X_new.get_support()]\n",
    "\n",
    "y_predict_1 = logreg.predict(X_test)\n",
    "y_predict_2 = Bagreg.predict(X_test)\n",
    "y_predict_3 = Bagreg_2.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"The AUC score is \", roc_auc_score(Y_test, y_predict_1))\n",
    "print(\"The AUC score is \", roc_auc_score(Y_test, y_predict_2))\n",
    "print(\"The AUC score is \", roc_auc_score(Y_test, y_predict_3))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "\n",
    "fpr[0], tpr[0], _ = roc_curve(Y_test, y_predict_1)\n",
    "fpr[1], tpr[1], _ = roc_curve(Y_test, y_predict_2)\n",
    "fpr[2], tpr[2], _ = roc_curve(Y_test, y_predict_3)\n",
    "\n",
    "\n",
    "roc_auc[0] = auc(fpr[0], tpr[0])\n",
    "roc_auc[1] = auc(fpr[1], tpr[1])\n",
    "roc_auc[2] = auc(fpr[2], tpr[2])\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr[0], tpr[0], label='Logistic Regression')\n",
    "plt.plot(fpr[1], tpr[1], label='Ensemble methods-Bagging KNN')\n",
    "plt.plot(fpr[2], tpr[2], label='Ensemble methods-Bagging Tree')\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
